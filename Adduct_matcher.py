#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ESI Adduct Matcher
Automatically identify adduct pairs in mass spectrometry data
"""

import pandas as pd
import numpy as np
from pathlib import Path
from typing import Optional, List, Dict, Tuple
import warnings
warnings.filterwarnings('ignore')


class Adduct_matcher:
    """ESI Adduct Matcher"""
    
    def __init__(self, ppm_tolerance: float = 20.0, custom_adduct_file: Optional[str] = None):
        """
        Initialize Adduct Matcher
        
        Parameters:
        -----------
        ppm_tolerance : float
            Mass error tolerance (ppm), default is 20 ppm
        custom_adduct_file : str, optional
            Path to custom adduct table Excel file
        """
        self.ppm_tolerance = ppm_tolerance / 1_000_000  # Convert to ratio
        self.adduct_table = self._load_adduct_table(custom_adduct_file)
        
        # Column information
        self.rt_col = None
        self.mz_col = None
        self.intensity_col = None
        self.all_columns = None
        
    def _create_adduct_table(self) -> pd.DataFrame:
        """Create default table with 23 common ESI adducts mass differences"""
        data = {
            'From': ['[M+H]+'] * 23,
            'To': [
                '[M+Li]+', '[M+NH4]+', '[M+Na]+', '[M+K]+', '[M+H3O]+',
                '[M+H2O+H]+', '[M+MeOH+H]+', '[M+EtOH+H]+', '[M+IPA+H]+',
                '[M+ACN+H]+', '[M+DMSO+H]+', '[M+H2O+Na]+', '[M+MeOH+Na]+',
                '[M+EtOH+Na]+', '[M+IPA+Na]+', '[M+ACN+Na]+', '[M+DMSO+Na]+',
                '[M+HCOOH+H]+', '[M+CH3COOH+H]+', '[M+H2CO3+H]+',
                '[M+H2SO4+H]+', '[M+Na+H]+', '[M+2Na-H]+'
            ],
            'Delta_Da': [
                6.00817839, 17.02654909, 21.98194424, 37.95588144, 18.01056467,
                18.01056468, 32.02621475, 46.04186481, 60.05751488, 41.0265491,
                78.01393599, 39.99250892, 54.00815898, 68.02380905, 82.03945911,
                63.00849334, 99.99588022, 46.0054793, 60.02112937, 62.00039392,
                97.96737972, 22.9892207, 43.96388847
            ]
        }
        return pd.DataFrame(data)
    
    def _load_adduct_table(self, custom_file: Optional[str] = None) -> pd.DataFrame:
        """
        Load adduct table from custom file or use default
        
        Parameters:
        -----------
        custom_file : str, optional
            Path to custom adduct table Excel file
            Expected columns: 'From', 'To', 'Delta_Da'
            
        Returns:
        --------
        pd.DataFrame
            Adduct table
        """
        if custom_file:
            try:
                # Load custom adduct table
                custom_df = pd.read_excel(custom_file)
                
                # Validate required columns
                required_cols = ['From', 'To', 'Delta_Da']
                if not all(col in custom_df.columns for col in required_cols):
                    print(f"âš  Warning: Custom adduct table missing required columns: {required_cols}")
                    print(f"  Using default adduct table instead.")
                    return self._create_adduct_table()
                
                # Filter valid rows
                custom_df = custom_df[required_cols].dropna()
                
                if len(custom_df) == 0:
                    print(f"âš  Warning: Custom adduct table is empty.")
                    print(f"  Using default adduct table instead.")
                    return self._create_adduct_table()
                
                print(f"âœ“ Loaded custom adduct table: {len(custom_df)} adducts")
                return custom_df
                
            except Exception as e:
                print(f"âš  Warning: Failed to load custom adduct table: {str(e)}")
                print(f"  Using default adduct table instead.")
                return self._create_adduct_table()
        else:
            # Use default adduct table
            return self._create_adduct_table()
    
    def load_data(self, file_path: str) -> pd.DataFrame:
        """
        Load data and automatically identify columns (supports Excel, CSV, TSV)
        
        Parameters:
        -----------
        file_path : str
            File path
            
        Returns:
        --------
        pd.DataFrame
            DataFrame with all columns
        """
        file_path = str(file_path)
        
        # Select reading method based on file extension
        if file_path.endswith('.csv'):
            df = pd.read_csv(file_path, encoding='utf-8-sig')
        elif file_path.endswith('.tsv') or file_path.endswith('.txt'):
            df = pd.read_csv(file_path, sep='\t', encoding='utf-8-sig')
        elif file_path.endswith(('.xlsx', '.xls', '.xlsm', '.xlsb')):
            df = pd.read_excel(file_path)
        else:
            raise ValueError(f"Unsupported file format. Supported: .xlsx, .xls, .xlsm, .xlsb, .csv, .tsv, .txt")
        
        # Auto-identify RT, m/z, Intensity columns
        rt_col = self._find_column(df.columns, [
            'rt', 'retention time', 'retention_time', 'retentiontime',
            'rt (min)', 'rt(min)', 'retention time (min)', 'time',
            'r.t.', 'r.t', 'ä¿ç•™æ™‚é–“', 'æ»¯ç•™æ™‚é–“'
        ])
        mz_col = self._find_column(df.columns, [
            'm/z', 'mz', 'm_z', 'mass', 'mass to charge',
            'precursor ion m/z', 'precursor m/z', 'precursormz',
            'è³ªé‡', 'è³ªè·æ¯”'
        ])
        intensity_col = self._find_column(df.columns, [
            'intensity', 'int', 'intens', 'abundance', 'abund', 'height', 'area',
            'precursor ion intensity', 'precursor intensity', 'precursorintensity',
            'å¼·åº¦', 'å³°é«˜', 'å³°é¢ç©'
        ])
        
        if not rt_col or not mz_col or not intensity_col:
            missing = []
            if not rt_col: missing.append("RT (Retention Time)")
            if not mz_col: missing.append("m/z (Mass-to-Charge)")
            if not intensity_col: missing.append("Intensity")
            
            available_cols = "\nAvailable columns: " + ", ".join(df.columns.tolist())
            raise ValueError(f"Cannot identify columns: {', '.join(missing)}\nPlease ensure headers contain these column names{available_cols}")
        
        # Mark main columns
        self.rt_col = rt_col
        self.mz_col = mz_col
        self.intensity_col = intensity_col
        self.all_columns = list(df.columns)
        
        print(f"âœ“ Successfully loaded file: {Path(file_path).name}")
        print(f"  Data shape: {df.shape[0]} rows Ã— {df.shape[1]} columns")
        print(f"\nIdentified columns:")
        print(f"  RT (Retention Time):  {rt_col}")
        print(f"  m/z (Mass-to-Charge): {mz_col}")
        print(f"  Intensity:            {intensity_col}")
        print(f"  Other columns kept:   {len(self.all_columns) - 3}")
        
        # Remove invalid data (only check m/z and intensity > 0, RT can be 0)
        original_count = len(df)
        df = df[(df[mz_col] > 0) & (df[intensity_col] > 0)]
        df = df.dropna(subset=[rt_col, mz_col, intensity_col])
        
        removed_count = original_count - len(df)
        if removed_count > 0:
            print(f"\nâš  Removed {removed_count} invalid rows (m/zâ‰¤0, Intensityâ‰¤0, or missing values)")
        
        print(f"âœ“ Valid data: {len(df)} rows\n")
        
        return df.reset_index(drop=True)
    
    def _find_column(self, columns: List[str], possible_names: List[str]) -> Optional[str]:
        """
        Find matching column name
        
        Parameters:
        -----------
        columns : list
            All column names
        possible_names : list
            List of possible column names
            
        Returns:
        --------
        str or None
            Found column name
        """
        for col in columns:
            col_lower = str(col).lower().strip()
            for name in possible_names:
                if name in col_lower:
                    return col
        return None
    
    def match_adducts(self, df: pd.DataFrame, rt_tolerance: float = 0.5) -> pd.DataFrame:
        """
        Match adducts, keep all original columns
        When multiple bases compete for the same pair, keep all matches (list all possibilities)
        
        Parameters:
        -----------
        df : pd.DataFrame
            DataFrame with mass spectrometry data
        rt_tolerance : float
            RT tolerance (minutes), default is 0.5 minutes
            
        Returns:
        --------
        pd.DataFrame
            DataFrame with adduct matching results, keeping all original columns
        """
        print("Starting adduct matching...")
        
        # ç¢ºä¿æ•¸æ“šæŒ‰RTæ’åº
        df = df.sort_values(by=self.rt_col).reset_index(drop=True)
        
        # å»ºç«‹çµæœåˆ—è¡¨
        results = []
        
        # å°æ¯å€‹æ•¸æ“šé»é€²è¡Œæ¯”å°
        for i, row in df.iterrows():
            current_rt = row[self.rt_col]
            current_mz = row[self.mz_col]
            current_intensity = row[self.intensity_col]
            
            # æ‰¾å‡ºç›¸åŒæˆ–æ¥è¿‘æ»¯ç•™æ™‚é–“çš„å…¶ä»–è¨Šè™Ÿ
            rt_mask = abs(df[self.rt_col] - current_rt) <= rt_tolerance
            nearby_peaks = df[rt_mask & (df.index != i)]
            
            # èˆ‡é™„è¿‘çš„peakæ¯”å°
            for _, nearby_peak in nearby_peaks.iterrows():
                nearby_rt = nearby_peak[self.rt_col]
                nearby_mz = nearby_peak[self.mz_col]
                nearby_intensity = nearby_peak[self.intensity_col]
                
                # è¨ˆç®—RTå·®ç•°ï¼ˆç”¨æ–¼å¾ŒçºŒç¯©é¸ï¼‰
                rt_diff = abs(current_rt - nearby_rt)
                
                # è¨ˆç®—è³ªé‡å·® (å¤§æ¸›å°)
                if nearby_mz > current_mz:
                    mz_diff = nearby_mz - current_mz
                    base_mz = current_mz
                    base_rt = current_rt
                    base_row = row
                    pair_mz = nearby_mz
                    pair_rt = nearby_rt
                    pair_row = nearby_peak
                else:
                    mz_diff = current_mz - nearby_mz
                    base_mz = nearby_mz
                    base_rt = nearby_rt
                    base_row = nearby_peak
                    pair_mz = current_mz
                    pair_rt = current_rt
                    pair_row = row
                
                # èˆ‡åŠ åˆç‰©è¡¨æ¯”å°
                for _, adduct in self.adduct_table.iterrows():
                    theoretical_delta = adduct['Delta_Da']
                    
                    # è¨ˆç®—ppmå®¹è¨±ç¯„åœ (ä½¿ç”¨è¼ƒå¤§çš„m/zä½œç‚ºåƒè€ƒï¼Œèˆ‡VBAç›¸åŒ)
                    reference_mz = max(current_mz, nearby_mz)  # ä½¿ç”¨è¼ƒå¤§çš„m/z
                    ppm_tolerance_da = self.ppm_tolerance * reference_mz  # è½‰æ›ç‚ºDa
                    
                    # æª¢æŸ¥è³ªé‡å·®æ˜¯å¦åœ¨å®¹è¨±ç¯„åœå…§
                    if abs(mz_diff - theoretical_delta) <= ppm_tolerance_da:
                        # è¨ˆç®—å¯¦éš›çš„PPMèª¤å·®ï¼ˆç”¨æ–¼å ±å‘Šï¼‰
                        ppm_error_value = abs(mz_diff - theoretical_delta) / reference_mz * 1_000_000
                        
                        # å»ºç«‹çµæœå­—å…¸ï¼ŒåŒ…å«æ‰€æœ‰åŸå§‹æ¬„ä½
                        result = {}
                        
                        # æ·»åŠ BaseåŒ–åˆç‰©çš„æ‰€æœ‰æ¬„ä½ï¼ˆåŠ ä¸ŠBase_å‰ç¶´ï¼‰
                        for col in self.all_columns:
                            result[f'Base_{col}'] = base_row[col]
                        
                        # æ·»åŠ PairåŒ–åˆç‰©çš„æ‰€æœ‰æ¬„ä½ï¼ˆåŠ ä¸ŠPair_å‰ç¶´ï¼‰
                        for col in self.all_columns:
                            result[f'Pair_{col}'] = pair_row[col]
                        
                        # æ·»åŠ æ¯”å°è³‡è¨Š
                        result['Base_Adduct'] = '[M+H]+'
                        result['Pair_Adduct'] = adduct['To']
                        result['Theoretical_Delta_Da'] = theoretical_delta
                        result['Observed_Delta_Da'] = mz_diff
                        result['PPM_Error'] = round(ppm_error_value, 2)
                        result['RT_Diff'] = rt_diff  # æ·»åŠ RTå·®ç•°ç”¨æ–¼ç¯©é¸
                        result['Reference_mz'] = reference_mz
                        result['Annotation'] = f"{adduct['To']} of Base (m/z {base_mz:.4f})"
                        
                        results.append(result)
        
        if results:
            results_df = pd.DataFrame(results)
            
            # ç§»é™¤é‡è¤‡çš„é…å°ï¼ˆåŒä¸€çµ„Base-Pair-Adductåªä¿ç•™ä¸€æ¬¡ï¼‰
            base_mz_col = f'Base_{self.mz_col}'
            base_rt_col = f'Base_{self.rt_col}'
            pair_mz_col = f'Pair_{self.mz_col}'
            pair_rt_col = f'Pair_{self.rt_col}'
            
            # å…ˆå»é™¤å®Œå…¨ç›¸åŒçš„é…å°
            results_df = results_df.drop_duplicates(
                subset=[base_mz_col, base_rt_col, pair_mz_col, pair_rt_col, 'Pair_Adduct'], 
                keep='first'
            ).reset_index(drop=True)
            
            # æ–¹æ¡ˆ2: ä¿ç•™æ‰€æœ‰é…å°ï¼Œä½†åœ¨åŒä¸€å€‹Baseæœ‰å¤šå€‹Pairæ™‚ï¼Œé¸RTæœ€è¿‘çš„
            # ç•¶ä¸€å€‹Baseæœ‰å¤šå€‹Pairå€™é¸æ™‚ï¼Œä¿ç•™RTæœ€æ¥è¿‘çš„
            results_df = results_df.sort_values('RT_Diff')
            results_df = results_df.drop_duplicates(
                subset=[base_mz_col, base_rt_col, 'Pair_Adduct'],
                keep='first'
            ).reset_index(drop=True)
            
            # ç•¶ä¸€å€‹Pairæœ‰å¤šå€‹Baseæ™‚ï¼Œä¿ç•™æ‰€æœ‰é…å°ï¼ˆä¸å»é‡ï¼‰
            # é€™æ¨£å¯ä»¥åˆ—å‡ºæ‰€æœ‰å¯èƒ½æ€§
            
            # ç§»é™¤RT_Diffæ¬„ä½ï¼ˆç”¨æˆ¶ä¸éœ€è¦çœ‹åˆ°ï¼‰
            results_df = results_df.drop(columns=['RT_Diff'])
            
            print(f"âœ“ æ‰¾åˆ° {len(results_df)} å€‹åŠ åˆç‰©é…å°")
            
            # é¡¯ç¤ºåŠ åˆç‰©é¡å‹çµ±è¨ˆ
            adduct_counts = results_df['Pair_Adduct'].value_counts()
            print(f"\nåŠ åˆç‰©é¡å‹åˆ†å¸ƒ:")
            for adduct, count in adduct_counts.head(5).items():
                print(f"  {adduct}: {count} å€‹")
            
            return results_df
        else:
            print("âš  æœªæ‰¾åˆ°ç¬¦åˆçš„åŠ åˆç‰©é…å°")
            return pd.DataFrame()
    
    def save_results(self, df: pd.DataFrame, original_file: str, 
                    results: pd.DataFrame, output_file: Optional[str] = None):
        """
        Save results to Excel file, marking matching results on original data
        
        Parameters:
        -----------
        df : pd.DataFrame
            Original data
        original_file : str
            Original file path
        results : pd.DataFrame
            Matching results
        output_file : str, optional
            Output file name, auto-generated if not specified
        """
        if output_file is None:
            # Auto-generate output file name
            file_path = Path(original_file)
            output_file = str(file_path.parent / f"{file_path.stem}_adduct_results.xlsx")
        
        print(f"\nSaving results to: {Path(output_file).name}")
        
        # æº–å‚™æ¨™è¨˜è³‡è¨Š
        df_marked = df.copy()
        
        # æ–°å¢è­˜åˆ¥æ¬„ä½
        df_marked['Adduct_Type'] = '[M+H]+'  # é è¨­éƒ½æ˜¯[M+H]+
        df_marked['Pair_mz'] = ''            # é…å°çš„m/zå€¼
        df_marked['PPM_Error'] = ''          # PPMèª¤å·®
        df_marked['Description'] = ''     # é…å°èªªæ˜
        df_marked['Is_Matched_Base'] = False  # æ˜¯å¦ç‚ºæœ‰é…å°çš„Base
        
        if not results.empty:
            # å»ºç«‹m/zåˆ°ç´¢å¼•çš„æ˜ å°„
            mz_col = self.mz_col
            rt_col = self.rt_col
            base_mz_col = f'Base_{mz_col}'
            pair_mz_col = f'Pair_{mz_col}'
            base_rt_col = f'Base_{rt_col}'
            pair_rt_col = f'Pair_{rt_col}'
            
            # å»ºç«‹Pairåˆ°å¤šå€‹Baseçš„æ˜ å°„å­—å…¸
            pair_to_bases = {}  # key: (pair_mz, pair_rt), value: list of (base_mz, adduct, ppm)
            
            for _, result_row in results.iterrows():
                base_mz = result_row[base_mz_col]
                base_rt = result_row[base_rt_col]
                pair_mz = result_row[pair_mz_col]
                pair_rt = result_row[pair_rt_col]
                adduct = result_row['Pair_Adduct']
                ppm = result_row['PPM_Error']
                
                pair_key = (pair_mz, pair_rt)
                if pair_key not in pair_to_bases:
                    pair_to_bases[pair_key] = []
                
                pair_to_bases[pair_key].append({
                    'base_mz': base_mz,
                    'adduct': adduct,
                    'ppm': ppm
                })
            
            # æ¨™è¨˜BaseåŒ–åˆç‰©ï¼ˆæœ‰é…å°çš„[M+H]+ï¼‰
            for _, result_row in results.iterrows():
                base_mz = result_row[base_mz_col]
                base_rt = result_row[base_rt_col]
                
                # åŒæ™‚æª¢æŸ¥ m/z å’Œ RT
                mask = (abs(df_marked[mz_col] - base_mz) < 0.0001) & \
                       (abs(df_marked[rt_col] - base_rt) < 0.0001)
                if mask.any():
                    df_marked.loc[mask, 'Is_Matched_Base'] = True
            
            # æ¨™è¨˜PairåŒ–åˆç‰©ï¼ˆæ¨™è¨˜ç‚ºå°æ‡‰çš„åŠ åˆç‰©é¡å‹ï¼Œå¯èƒ½æœ‰å¤šå€‹ï¼‰
            for pair_key, base_list in pair_to_bases.items():
                pair_mz, pair_rt = pair_key
                
                # æ‰¾åˆ°å°æ‡‰çš„Pairè¡Œ
                mask = (abs(df_marked[mz_col] - pair_mz) < 0.0001) & \
                       (abs(df_marked[rt_col] - pair_rt) < 0.0001)
                
                if mask.any():
                    # å¦‚æœæœ‰å¤šå€‹Baseï¼ŒæŒ‰PPMæ’åºï¼ˆæœ€å°çš„æœ€å¯èƒ½ï¼‰
                    base_list_sorted = sorted(base_list, key=lambda x: x['ppm'])
                    
                    # åˆä½µæ‰€æœ‰åŠ åˆç‰©é¡å‹
                    adduct_types = '; '.join([b['adduct'] for b in base_list_sorted])
                    
                    # åˆä½µæ‰€æœ‰é…å°èªªæ˜ï¼ˆä¸åŒ…å«PPMè³‡è¨Šï¼‰
                    descriptions = '; '.join([
                        f"{b['adduct']} of Base m/z {b['base_mz']:.4f}"
                        for b in base_list_sorted
                    ])
                    
                    # åˆä½µæ‰€æœ‰å¯èƒ½çš„ Base m/zï¼ˆç”¨åˆ†è™Ÿåˆ†éš”ï¼‰
                    pair_mz_list = '; '.join([f"{b['base_mz']:.4f}" for b in base_list_sorted])
                    
                    # åˆä½µæ‰€æœ‰PPMèª¤å·®ï¼ˆç”¨åˆ†è™Ÿåˆ†éš”ï¼‰
                    ppm_list = '; '.join([f"{b['ppm']:.2f}" for b in base_list_sorted])
                    
                    df_marked.loc[mask, 'Adduct_Type'] = adduct_types
                    df_marked.loc[mask, 'Pair_mz'] = pair_mz_list  # åˆ—å‡ºæ‰€æœ‰Base m/z
                    df_marked.loc[mask, 'PPM_Error'] = ppm_list  # åˆ—å‡ºæ‰€æœ‰PPMèª¤å·®
                    df_marked.loc[mask, 'Description'] = descriptions
        
        # å¯«å…¥Excelä¸¦è¨­å®šæ ¼å¼
        with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
            # Sheet 1: å¯«å…¥æ¨™è¨˜å¾Œçš„åŸå§‹æ•¸æ“šï¼ˆä¸åŒ…å«Is_Matched_Baseæ¬„ä½ï¼‰
            df_output = df_marked.drop(columns=['Is_Matched_Base'])
            df_output.to_excel(writer, sheet_name='All_Feature_Annotated', index=False)
            
            # Sheet 2: åªä¿ç•™éåŠ åˆç‰©çš„è¨Šè™Ÿï¼ˆç™½è‰²èƒŒæ™¯ï¼šé»‘è‰²å’Œç´…è‰²å­—é«”ï¼‰
            df_non_adduct = df_marked[df_marked['Adduct_Type'] == '[M+H]+'].copy()
            df_non_adduct = df_non_adduct.drop(columns=['Is_Matched_Base'])
            df_non_adduct.to_excel(writer, sheet_name='Non_Adduct_Feature', index=False)
            
            # å–å¾—workbookå’Œworksheetä»¥è¨­å®šæ ¼å¼
            from openpyxl.styles import PatternFill, Font
            workbook = writer.book
            
            # æ ¼å¼åŒ– Sheet 1: All_Feature_Annotated
            worksheet1 = writer.sheets['All_Feature_Annotated']
            
            if not results.empty:
                # è¨­å®šé¡è‰²
                yellow_fill = PatternFill(start_color='FFFF00', end_color='FFFF00', fill_type='solid')
                red_font = Font(color='FF0000', bold=True)
                
                # éæ­·æ¯ä¸€è¡Œè¨­å®šæ ¼å¼
                for row_idx in range(2, len(df_marked) + 2):
                    adduct_type_value = df_marked.iloc[row_idx-2]['Adduct_Type']
                    is_matched_base = df_marked.iloc[row_idx-2]['Is_Matched_Base']
                    
                    if adduct_type_value == '[M+H]+' and is_matched_base:
                        # æœ‰é…å°çš„BaseåŒ–åˆç‰© - ç´…è‰²å­—é«”
                        for col_idx in range(1, len(df_output.columns) + 1):
                            cell = worksheet1.cell(row=row_idx, column=col_idx)
                            cell.font = red_font
                    elif adduct_type_value and adduct_type_value != '[M+H]+':
                        # PairåŒ–åˆç‰© - é»ƒè‰²èƒŒæ™¯
                        for col_idx in range(1, len(df_output.columns) + 1):
                            cell = worksheet1.cell(row=row_idx, column=col_idx)
                            cell.fill = yellow_fill
                
                # æ ¼å¼åŒ– Intensity æ¬„ä½ç‚ºç§‘å­¸è¨˜è™Ÿ
                intensity_col_idx = list(df_output.columns).index(self.intensity_col) + 1
                for row in range(2, len(df_marked) + 2):
                    cell = worksheet1.cell(row=row, column=intensity_col_idx)
                    cell.number_format = '0.00E+00'
                
                # æ ¼å¼åŒ– PPM_Error æ¬„ä½
                if 'PPM_Error' in df_output.columns:
                    ppm_col_idx = list(df_output.columns).index('PPM_Error') + 1
                    for row in range(2, len(df_marked) + 2):
                        cell = worksheet1.cell(row=row, column=ppm_col_idx)
                        if cell.value and cell.value != '':
                            cell.number_format = '0.00'
                
                # èª¿æ•´æ¬„å¯¬ - Sheet 1
                for column in worksheet1.columns:
                    max_length = 0
                    column_letter = column[0].column_letter
                    for cell in column:
                        try:
                            if len(str(cell.value)) > max_length:
                                max_length = len(str(cell.value))
                        except:
                            pass
                    adjusted_width = min(max_length + 2, 50)
                    worksheet1.column_dimensions[column_letter].width = adjusted_width
            
            # æ ¼å¼åŒ– Sheet 2: Non_Adduct_Feature
            worksheet2 = writer.sheets['Non_Adduct_Feature']
            
            if not results.empty and len(df_non_adduct) > 0:
                red_font = Font(color='FF0000', bold=True)
                
                # æ¨™è¨˜æœ‰é…å°çš„BaseåŒ–åˆç‰©ï¼ˆç´…è‰²å­—é«”ï¼‰
                non_adduct_with_match = df_marked[
                    (df_marked['Adduct_Type'] == '[M+H]+') & 
                    (df_marked['Is_Matched_Base'] == True)
                ].index.tolist()
                
                # å»ºç«‹ç´¢å¼•æ˜ å°„
                non_adduct_indices = df_non_adduct.index.tolist()
                
                for row_idx in range(2, len(df_non_adduct) + 2):
                    original_idx = non_adduct_indices[row_idx - 2]
                    
                    if original_idx in non_adduct_with_match:
                        # æœ‰é…å°çš„Base - ç´…è‰²å­—é«”
                        for col_idx in range(1, len(df_non_adduct.columns) + 1):
                            cell = worksheet2.cell(row=row_idx, column=col_idx)
                            cell.font = red_font
                
                # æ ¼å¼åŒ– Intensity æ¬„ä½
                if self.intensity_col in df_non_adduct.columns:
                    intensity_col_idx = list(df_non_adduct.columns).index(self.intensity_col) + 1
                    for row in range(2, len(df_non_adduct) + 2):
                        cell = worksheet2.cell(row=row, column=intensity_col_idx)
                        cell.number_format = '0.00E+00'
                
                # èª¿æ•´æ¬„å¯¬ - Sheet 2
                for column in worksheet2.columns:
                    max_length = 0
                    column_letter = column[0].column_letter
                    for cell in column:
                        try:
                            if len(str(cell.value)) > max_length:
                                max_length = len(str(cell.value))
                        except:
                            pass
                    adjusted_width = min(max_length + 2, 50)
                    worksheet2.column_dimensions[column_letter].width = adjusted_width
        
        print(f"âœ“ Results saved successfully!")
        print(f"  Sheet 1: All_Feature_Annotated - All peaks with annotations")
        print(f"  Sheet 2: Non_Adduct_Feature - Only [M+H]+ peaks (no adduct peaks)")
        if not results.empty:
            base_count = df_marked['Is_Matched_Base'].sum()
            pair_count = (df_marked['Adduct_Type'] != '[M+H]+').sum()
            unmatched_count = len(df_marked) - base_count - pair_count
            non_adduct_total = len(df_non_adduct)
            
            print(f"\n  All_Feature_Annotated:")
            print(f"    â€¢ Black text = Unmatched [M+H]+ ({unmatched_count} peaks)")
            print(f"    â€¢ Red text = Matched Base compounds ([M+H]+) ({base_count} peaks)")
            print(f"    â€¢ Yellow background = Matched adducts ({pair_count} peaks)")
            print(f"\n  Non_Adduct_Feature:")
            print(f"    â€¢ Total [M+H]+ peaks: {non_adduct_total}")
            print(f"    â€¢ Black text = Unmatched ({unmatched_count} peaks)")
            print(f"    â€¢ Red text = Has adduct pair ({base_count} peaks)")
        else:
            print(f"    â€¢ No matching results found")
    
    def process(self, file_path: str, rt_tolerance: float = 0.5, 
                output_file: Optional[str] = None) -> pd.DataFrame:
        """
        Complete processing workflow
        
        Parameters:
        -----------
        file_path : str
            Input file path
        rt_tolerance : float
            RT tolerance (minutes)
        output_file : str, optional
            Output file name
            
        Returns:
        --------
        pd.DataFrame
            Matching results
        """
        print("="*70)
        print("ESI Adduct Matcher")
        print("="*70 + "\n")
        
        # Load data
        df = self.load_data(file_path)
        
        # Show data preview
        print("Data preview (first 5 rows):")
        print(df.head().to_string(index=False))
        print()
        
        # Execute matching
        results = self.match_adducts(df, rt_tolerance=rt_tolerance)
        
        # Save results
        if not results.empty:
            self.save_results(df, file_path, results, output_file)
            
            print("\n" + "="*70)
            print("âœ“ Analysis completed!")
            print("="*70)
            
            # Show key statistics
            print(f"\nFound {len(results)} adduct pairs")
            print(f"Average PPM error: {results['PPM_Error'].mean():.2f}")
            print(f"PPM error range: {results['PPM_Error'].min():.2f} - {results['PPM_Error'].max():.2f}")
        else:
            print("\n" + "="*70)
            print("âš  No matching adduct pairs found")
            print("="*70)
            print("\nSuggestions:")
            print("  1. Increase RT tolerance (e.g., 0.1 or 0.2)")
            print("  2. Increase PPM tolerance (e.g., 30 or 50)")
            print("  3. Check data quality")
        
        return results


class Adduct_matcherGUI:
    """Graphical User Interface"""
    
    def __init__(self, root):
        import tkinter as tk
        from tkinter import filedialog, messagebox, ttk
        
        self.tk = tk
        self.ttk = ttk
        self.filedialog = filedialog
        self.messagebox = messagebox
        
        self.root = root
        self.root.title("ESI Adduct Matcher")
        self.root.geometry("700x750")
        self.root.configure(bg='#f0f4f8')
        
        self.input_file = None
        self.adduct_file = None
        
        # ç¾ä»£é…è‰²æ–¹æ¡ˆ
        self.colors = {
            'primary': '#2196F3',      # è—è‰²
            'secondary': '#4CAF50',    # ç¶ è‰²
            'accent': '#FF9800',       # æ©™è‰²
            'danger': '#F44336',       # ç´…è‰²
            'bg_light': '#f0f4f8',     # æ·ºç°è—
            'bg_white': '#ffffff',     # ç™½è‰²
            'text_dark': '#2c3e50',    # æ·±ç°
            'text_light': '#7f8c8d',   # æ·ºç°
            'border': '#e0e6ed'        # é‚Šæ¡†ç°
        }
        
        self.create_widgets()
    
    def create_widgets(self):
        tk = self.tk
        ttk = self.ttk
        
        # è¨­å®š ttk æ¨£å¼
        style = ttk.Style()
        style.theme_use('clam')
        
        # æ¨™é¡Œå€åŸŸ
        title_frame = tk.Frame(self.root, bg=self.colors['primary'], height=80)
        title_frame.pack(fill="x", pady=0)
        title_frame.pack_propagate(False)
        
        title_label = tk.Label(
            title_frame,
            text="ğŸ”¬ ESI Adduct Matcher",
            font=("Segoe UI", 20, "bold"),
            bg=self.colors['primary'],
            fg='white'
        )
        title_label.pack(expand=True)
        
        subtitle_label = tk.Label(
            title_frame,
            text="Identify adduct pairs in mass spectrometry data",
            font=("Segoe UI", 9),
            bg=self.colors['primary'],
            fg='white'
        )
        subtitle_label.pack()
        
        # ä¸»è¦å…§å®¹å€åŸŸ
        main_frame = tk.Frame(self.root, bg=self.colors['bg_light'])
        main_frame.pack(fill="both", expand=True, padx=20, pady=20)
        
        # Step 1: æª”æ¡ˆé¸æ“‡å€åŸŸ
        step1_frame = tk.LabelFrame(
            main_frame,
            text="  Step 1: Select Files  ",
            font=("Segoe UI", 11, "bold"),
            bg=self.colors['bg_white'],
            fg=self.colors['text_dark'],
            relief="flat",
            borderwidth=2,
            highlightbackground=self.colors['border'],
            highlightthickness=1
        )
        step1_frame.pack(fill="x", pady=(0, 15))
        
        # å…§éƒ¨å®¹å™¨
        step1_inner = tk.Frame(step1_frame, bg=self.colors['bg_white'])
        step1_inner.pack(fill="x", padx=15, pady=15)
        
        # è¼¸å…¥æª”æ¡ˆ
        input_container = tk.Frame(step1_inner, bg=self.colors['bg_white'])
        input_container.pack(fill="x", pady=(0, 10))
        
        tk.Label(
            input_container,
            text="ğŸ“ Input Data File:",
            font=("Segoe UI", 10, "bold"),
            bg=self.colors['bg_white'],
            fg=self.colors['text_dark']
        ).pack(anchor="w", pady=(0, 5))
        
        input_row = tk.Frame(input_container, bg=self.colors['bg_white'])
        input_row.pack(fill="x")
        
        self.file_label = tk.Label(
            input_row,
            text="No file selected",
            font=("Segoe UI", 9),
            bg=self.colors['bg_light'],
            fg=self.colors['text_light'],
            anchor="w",
            padx=10,
            pady=8,
            relief="flat"
        )
        self.file_label.pack(side="left", fill="x", expand=True, padx=(0, 10))
        
        tk.Button(
            input_row,
            text="Browse",
            command=self.select_file,
            bg=self.colors['primary'],
            fg='white',
            font=("Segoe UI", 9, "bold"),
            relief="flat",
            padx=20,
            pady=8,
            cursor="hand2",
            activebackground='#1976D2',
            activeforeground='white'
        ).pack(side="right")
        
        # åŠ åˆç‰©è¡¨æª”æ¡ˆ
        adduct_container = tk.Frame(step1_inner, bg=self.colors['bg_white'])
        adduct_container.pack(fill="x")
        
        tk.Label(
            adduct_container,
            text="ğŸ“‹ Adduct Table (Optional):",
            font=("Segoe UI", 10, "bold"),
            bg=self.colors['bg_white'],
            fg=self.colors['text_dark']
        ).pack(anchor="w", pady=(0, 5))
        
        adduct_row = tk.Frame(adduct_container, bg=self.colors['bg_white'])
        adduct_row.pack(fill="x")
        
        self.adduct_label = tk.Label(
            adduct_row,
            text="Using default (23 adducts)",
            font=("Segoe UI", 9),
            bg=self.colors['bg_light'],
            fg=self.colors['text_light'],
            anchor="w",
            padx=10,
            pady=8,
            relief="flat"
        )
        self.adduct_label.pack(side="left", fill="x", expand=True, padx=(0, 10))
        
        tk.Button(
            adduct_row,
            text="Browse",
            command=self.select_adduct_file,
            bg=self.colors['accent'],
            fg='white',
            font=("Segoe UI", 9, "bold"),
            relief="flat",
            padx=20,
            pady=8,
            cursor="hand2",
            activebackground='#F57C00',
            activeforeground='white'
        ).pack(side="right")
        
        # Step 2: åƒæ•¸è¨­å®šå€åŸŸ
        step2_frame = tk.LabelFrame(
            main_frame,
            text="  Step 2: Parameter Settings  ",
            font=("Segoe UI", 11, "bold"),
            bg=self.colors['bg_white'],
            fg=self.colors['text_dark'],
            relief="flat",
            borderwidth=2,
            highlightbackground=self.colors['border'],
            highlightthickness=1
        )
        step2_frame.pack(fill="x", pady=(0, 15))
        
        step2_inner = tk.Frame(step2_frame, bg=self.colors['bg_white'])
        step2_inner.pack(fill="x", padx=15, pady=15)
        
        # åƒæ•¸ç¶²æ ¼
        param_grid = tk.Frame(step2_inner, bg=self.colors['bg_white'])
        param_grid.pack(fill="x")
        
        # PPMå®¹å·®
        ppm_frame = tk.Frame(param_grid, bg=self.colors['bg_white'])
        ppm_frame.pack(side="left", expand=True, fill="x", padx=(0, 10))
        
        tk.Label(
            ppm_frame,
            text="âš™ï¸ PPM Tolerance:",
            font=("Segoe UI", 10, "bold"),
            bg=self.colors['bg_white'],
            fg=self.colors['text_dark']
        ).pack(anchor="w", pady=(0, 5))
        
        self.ppm_tolerance_var = tk.StringVar(value="20")
        ppm_entry = tk.Entry(
            ppm_frame,
            textvariable=self.ppm_tolerance_var,
            font=("Segoe UI", 10),
            bg=self.colors['bg_light'],
            fg=self.colors['text_dark'],
            relief="flat",
            justify="center"
        )
        ppm_entry.pack(fill="x", ipady=8)
        
        # RTå®¹å·®
        rt_frame = tk.Frame(param_grid, bg=self.colors['bg_white'])
        rt_frame.pack(side="left", expand=True, fill="x")
        
        tk.Label(
            rt_frame,
            text="â±ï¸ RT Tolerance (min):",
            font=("Segoe UI", 10, "bold"),
            bg=self.colors['bg_white'],
            fg=self.colors['text_dark']
        ).pack(anchor="w", pady=(0, 5))
        
        self.rt_tolerance_var = tk.StringVar(value="0.5")
        rt_entry = tk.Entry(
            rt_frame,
            textvariable=self.rt_tolerance_var,
            font=("Segoe UI", 10),
            bg=self.colors['bg_light'],
            fg=self.colors['text_dark'],
            relief="flat",
            justify="center"
        )
        rt_entry.pack(fill="x", ipady=8)
        
        # Step 3: åŸ·è¡ŒæŒ‰éˆ•
        step3_frame = tk.Frame(main_frame, bg=self.colors['bg_light'])
        step3_frame.pack(fill="x", pady=(0, 15))
        
        self.run_button = tk.Button(
            step3_frame,
            text="â–¶ï¸  Start Matching",
            command=self.process_data,
            bg=self.colors['secondary'],
            fg='white',
            font=("Segoe UI", 12, "bold"),
            relief="flat",
            padx=40,
            pady=15,
            cursor="hand2",
            activebackground='#45a049',
            activeforeground='white'
        )
        self.run_button.pack(expand=True)
        
        # ç‹€æ…‹é¡¯ç¤ºå€åŸŸ
        status_frame = tk.LabelFrame(
            main_frame,
            text="  Status & Results  ",
            font=("Segoe UI", 11, "bold"),
            bg=self.colors['bg_white'],
            fg=self.colors['text_dark'],
            relief="flat",
            borderwidth=2,
            highlightbackground=self.colors['border'],
            highlightthickness=1
        )
        status_frame.pack(fill="both", expand=True)
        
        status_inner = tk.Frame(status_frame, bg=self.colors['bg_white'])
        status_inner.pack(fill="both", expand=True, padx=10, pady=10)
        
        # ä½¿ç”¨Text widgeté¡¯ç¤ºç‹€æ…‹
        self.status_text = tk.Text(
            status_inner,
            height=12,
            font=("Consolas", 9),
            bg='#f8f9fa',
            fg=self.colors['text_dark'],
            relief="flat",
            wrap="word",
            state="disabled",
            padx=10,
            pady=10
        )
        self.status_text.pack(fill="both", expand=True)
        
        # åˆå§‹è¨Šæ¯
        self.update_status("ğŸ‘‹ Welcome! Please select your data file to begin.")
    
    def select_file(self):
        """Select input file"""
        file_path = self.filedialog.askopenfilename(
            title="Select mass spectrometry data file",
            filetypes=[
                ("All supported formats", "*.xlsx *.xls *.xlsm *.xlsb *.csv *.tsv *.txt"),
                ("Excel files", "*.xlsx *.xls *.xlsm *.xlsb"),
                ("CSV files", "*.csv"),
                ("TSV files", "*.tsv *.txt"),
                ("All files", "*.*")
            ]
        )
        
        if file_path:
            self.input_file = file_path
            self.file_label.config(text=Path(file_path).name, fg="black")
    
    def select_adduct_file(self):
        """Select custom adduct table file"""
        file_path = self.filedialog.askopenfilename(
            title="Select custom adduct table (Excel)",
            filetypes=[
                ("Excel files", "*.xlsx *.xls *.xlsm *.xlsb"),
                ("All files", "*.*")
            ]
        )
        
        if file_path:
            self.adduct_file = file_path
            self.adduct_label.config(text=Path(file_path).name, fg="black")
    
    def update_status(self, message):
        """æ›´æ–°ç‹€æ…‹é¡¯ç¤º"""
        self.status_text.config(state="normal")
        self.status_text.insert("end", message + "\n")
        self.status_text.see("end")
        self.status_text.config(state="disabled")
        self.root.update()
    
    def process_data(self):
        """Process data"""
        if not self.input_file:
            self.messagebox.showerror("âŒ Error", "Please select an input file first!")
            return
        
        try:
            # æ¸…ç©ºç‹€æ…‹
            self.status_text.config(state="normal")
            self.status_text.delete(1.0, "end")
            self.status_text.config(state="disabled")
            
            # ç¦ç”¨æŒ‰éˆ•é˜²æ­¢é‡è¤‡é»æ“Š
            self.run_button.config(state="disabled", bg='#cccccc')
            self.root.update()
            
            # è®€å–åƒæ•¸
            ppm_tol = float(self.ppm_tolerance_var.get())
            rt_tol = float(self.rt_tolerance_var.get())
            
            self.update_status("="*60)
            self.update_status("ğŸš€ Starting process...")
            self.update_status("="*60)
            
            # Create matcher with optional custom adduct table
            matcher = Adduct_matcher(ppm_tolerance=ppm_tol, custom_adduct_file=self.adduct_file)
            
            # è¼‰å…¥æ•¸æ“š
            self.update_status("\nğŸ“‚ Loading data...")
            df = matcher.load_data(self.input_file)
            
            # é¡¯ç¤ºè­˜åˆ¥çš„æ¬„ä½
            self.update_status(f"\nâœ… Identified columns:")
            self.update_status(f"  â€¢ RT: {matcher.rt_col}")
            self.update_status(f"  â€¢ m/z: {matcher.mz_col}")
            self.update_status(f"  â€¢ Intensity: {matcher.intensity_col}")
            self.update_status(f"  â€¢ Other columns kept: {len(matcher.all_columns) - 3}")
            
            # åŸ·è¡Œæ¯”å°
            self.update_status("\nğŸ” Executing adduct matching...")
            results = matcher.match_adducts(df, rt_tolerance=rt_tol)
            
            if not results.empty:
                # é¡¯ç¤ºåŠ åˆç‰©é¡å‹çµ±è¨ˆ
                adduct_counts = results['Pair_Adduct'].value_counts()
                self.update_status(f"\nğŸ“Š Adduct type distribution:")
                for adduct, count in adduct_counts.head(5).items():
                    self.update_status(f"  â€¢ {adduct}: {count} peaks")
                
                # ç”Ÿæˆè¼¸å‡ºæª”å
                input_path = Path(self.input_file)
                output_path = input_path.parent / f"{input_path.stem}_adduct_results.xlsx"
                
                # å„²å­˜çµæœ
                self.update_status("\nğŸ’¾ Saving results...")
                matcher.save_results(df, self.input_file, results, str(output_path))
                
                # é¡¯ç¤ºçµ±è¨ˆ
                self.update_status("\n" + "="*60)
                self.update_status("âœ… Processing completed!")
                self.update_status("="*60)
                self.update_status(f"\nğŸ‰ Found {len(results)} adduct pairs")
                self.update_status(f"ğŸ“ˆ Average PPM error: {results['PPM_Error'].mean():.2f}")
                self.update_status(f"ğŸ“Š PPM error range: {results['PPM_Error'].min():.2f} - {results['PPM_Error'].max():.2f}")
                self.update_status(f"\nğŸ’¾ Results saved to:\n   {output_path}")
                
                self.messagebox.showinfo(
                    "âœ… Completed", 
                    f"Processing completed successfully!\n\n"
                    f"ğŸ“Š Found {len(results)} adduct pairs\n\n"
                    f"ğŸ’¾ Results saved to:\n{output_path.name}"
                )
            else:
                self.update_status("\n" + "="*60)
                self.update_status("âš ï¸ No matching adduct pairs found")
                self.update_status("="*60)
                self.update_status("\nğŸ’¡ Suggestions:")
                self.update_status("  1ï¸âƒ£ Increase RT tolerance (e.g., 1.0 or 2.0)")
                self.update_status("  2ï¸âƒ£ Increase PPM tolerance (e.g., 30 or 50)")
                self.update_status("  3ï¸âƒ£ Check data quality")
                
                self.messagebox.showwarning(
                    "âš ï¸ Notice", 
                    "No matching adduct pairs found\n\n"
                    "Please try adjusting parameters or check data quality"
                )
            
        except Exception as e:
            self.messagebox.showerror("âŒ Error", f"Error during processing:\n\n{str(e)}")
            self.update_status(f"\nâŒ Error: {str(e)}")
        finally:
            # é‡æ–°å•Ÿç”¨æŒ‰éˆ•
            self.run_button.config(state="normal", bg=self.colors['secondary'])


def main():
    """ä¸»ç¨‹å¼"""
    import tkinter as tk
    from tkinter import filedialog, messagebox
    
    root = tk.Tk()
    app = Adduct_matcherGUI(root)
    root.mainloop()


if __name__ == "__main__":
    main()
